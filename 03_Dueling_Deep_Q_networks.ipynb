{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Dueling_Deep_Q_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0V3kpuayiRk29Ra1cHOYl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasHagstrom79/PyTorch-Lightning/blob/main/03_Dueling_Deep_Q_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dueling Deep Q-Networks\n"
      ],
      "metadata": {
        "id": "YnGXLweZHHC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb\n",
        "\n",
        "!pip install pygame gym==0.17.3 pytorch-lightning==1.6.0 pyvirtualdisplay\n",
        "\n",
        "!pip install git+https://github.com/GrupoTuring/PyGame-Learning-Environment\n",
        "!pip install git+https://github.com/lusob/gym-ple"
      ],
      "metadata": {
        "id": "KiizT2qQHe39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup viryual display"
      ],
      "metadata": {
        "id": "OzckMBfCHiTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display(visible=False, size=(1400, 900)).start()"
      ],
      "metadata": {
        "id": "5KvWZEDgHoEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import the necessary code libraries"
      ],
      "metadata": {
        "id": "3guYK0JCHtgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import random\n",
        "import gym\n",
        "import gym_ple\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "from collections import deque, namedtuple\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import IterableDataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "\n",
        "from gym.wrappers import TransformObservation\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "num_gpus = torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "eWCLaaHEHyrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb#scrollTo=gKc1FNhKiVJX\n",
        "\n",
        "def display_video(frames, framerate=30):\n",
        "  height, width, _ = frames[0].shape\n",
        "  dpi = 70\n",
        "  orig_backend = matplotlib.get_backend()\n",
        "  matplotlib.use('Agg')\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
        "  matplotlib.use(orig_backend)\n",
        "  ax.set_axis_off()\n",
        "  ax.set_aspect('equal')\n",
        "  ax.set_position([0, 0, 1, 1])\n",
        "  im = ax.imshow(frames[0])\n",
        "  def update(frame):\n",
        "    im.set_data(frame)\n",
        "    return [im]\n",
        "  interval = 1000/framerate\n",
        "  anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
        "                                  interval=interval, blit=True, repeat=False)\n",
        "  return HTML(anim.to_html5_video())"
      ],
      "metadata": {
        "id": "9aDqmhzgH0tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the Deep Q-Network"
      ],
      "metadata": {
        "id": "0Ujwt6QYH0_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M64qKWmeH5yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the policy"
      ],
      "metadata": {
        "id": "NX9kqpqWH6xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Do2JEliMH_xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the replay buffer"
      ],
      "metadata": {
        "id": "9LqUti1eIBlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kQtAFh69IFUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q2QG7IXkIF9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the environment"
      ],
      "metadata": {
        "id": "r2N9EtIcIGh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RunningMeanStd:\n",
        "    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
        "    def __init__(self, epsilon=1e-4, shape=()):\n",
        "        self.mean = np.zeros(shape, \"float64\")\n",
        "        self.var = np.ones(shape, \"float64\")\n",
        "        self.count = epsilon\n",
        "\n",
        "    def update(self, x):\n",
        "        batch_mean = np.mean(x, axis=0)\n",
        "        batch_var = np.var(x, axis=0)\n",
        "        batch_count = x.shape[0]\n",
        "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
        "\n",
        "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
        "        self.mean, self.var, self.count = update_mean_var_count_from_moments(\n",
        "            self.mean, self.var, self.count, batch_mean, batch_var, batch_count\n",
        "        )\n",
        "\n",
        "\n",
        "def update_mean_var_count_from_moments(\n",
        "    mean, var, count, batch_mean, batch_var, batch_count\n",
        "):\n",
        "    delta = batch_mean - mean\n",
        "    tot_count = count + batch_count\n",
        "\n",
        "    new_mean = mean + delta * batch_count / tot_count\n",
        "    m_a = var * count\n",
        "    m_b = batch_var * batch_count\n",
        "    M2 = m_a + m_b + np.square(delta) * count * batch_count / tot_count\n",
        "    new_var = M2 / tot_count\n",
        "    new_count = tot_count\n",
        "\n",
        "    return new_mean, new_var, new_count\n",
        "\n",
        "\n",
        "class NormalizeObservation(gym.core.Wrapper):\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        epsilon=1e-8,\n",
        "    ):\n",
        "        super().__init__(env)\n",
        "        self.num_envs = getattr(env, \"num_envs\", 1)\n",
        "        self.is_vector_env = getattr(env, \"is_vector_env\", False)\n",
        "        if self.is_vector_env:\n",
        "            self.obs_rms = RunningMeanStd(shape=self.single_observation_space.shape)\n",
        "        else:\n",
        "            self.obs_rms = RunningMeanStd(shape=self.observation_space.shape)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, rews, dones, infos = self.env.step(action)\n",
        "        if self.is_vector_env:\n",
        "            obs = self.normalize(obs)\n",
        "        else:\n",
        "            obs = self.normalize(np.array([obs]))[0]\n",
        "        return obs, rews, dones, infos\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return_info = kwargs.get(\"return_info\", False)\n",
        "        if return_info:\n",
        "            obs, info = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            obs = self.env.reset(**kwargs)\n",
        "        if self.is_vector_env:\n",
        "            obs = self.normalize(obs)\n",
        "        else:\n",
        "            obs = self.normalize(np.array([obs]))[0]\n",
        "        if not return_info:\n",
        "            return obs\n",
        "        else:\n",
        "            return obs, info\n",
        "\n",
        "    def normalize(self, obs):\n",
        "        self.obs_rms.update(obs)\n",
        "        return (obs - self.obs_rms.mean) / np.sqrt(self.obs_rms.var + self.epsilon)\n",
        "\n",
        "\n",
        "class NormalizeReward(gym.core.Wrapper):\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        gamma=0.99,\n",
        "        epsilon=1e-8,\n",
        "    ):\n",
        "        super().__init__(env)\n",
        "        self.num_envs = getattr(env, \"num_envs\", 1)\n",
        "        self.is_vector_env = getattr(env, \"is_vector_env\", False)\n",
        "        self.return_rms = RunningMeanStd(shape=())\n",
        "        self.returns = np.zeros(self.num_envs)\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, rews, dones, infos = self.env.step(action)\n",
        "        if not self.is_vector_env:\n",
        "            rews = np.array([rews])\n",
        "        self.returns = self.returns * self.gamma + rews\n",
        "        rews = self.normalize(rews)\n",
        "        self.returns[dones] = 0.0\n",
        "        if not self.is_vector_env:\n",
        "            rews = rews[0]\n",
        "        return obs, rews, dones, infos\n",
        "\n",
        "    def normalize(self, rews):\n",
        "        self.return_rms.update(self.returns)\n",
        "        return rews / np.sqrt(self.return_rms.var + self.epsilon)"
      ],
      "metadata": {
        "id": "nceNjFnwIJJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0Ue2_jWIMKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IuNh6DNdIMQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c_oEz7iaIMWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hfxYlqTNIMct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fx0cny8FIMi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yZbFIL0eIMpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DLu1sV86IMv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pBvL3Ox1IM2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the Deep Q-Learning algorithm"
      ],
      "metadata": {
        "id": "01_edtJgIOgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yaiD-0ljIT1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Purge logs and run the visualization tool (Tensorboard)"
      ],
      "metadata": {
        "id": "H0yIXoV4IVxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bnRVpixDIYPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train the policy"
      ],
      "metadata": {
        "id": "K2_9ZqonIZIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pJAXZ9AJIa9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Check the resulting policy"
      ],
      "metadata": {
        "id": "43hbfqswIcJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VL1DwTqyIekl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kDJo2go5IfSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "22e0IYgLIfX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}